{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2dec9d",
   "metadata": {},
   "source": [
    "# ECG-Pytorch-Ver2.0\n",
    "\n",
    "@create 2021-09-13\n",
    "@author 孙寒石\n",
    "@env Pytorch 1.9.0 Python 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a69dd",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a3bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692deb4e",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430755c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  800\n",
      "X_test  :  200\n",
      "shape of X_train :  (1, 3600)\n",
      "shape of y_train :  (800,)\n",
      "shape of X_test :  (200, 1, 3600)\n",
      "shape of y_test :  (200,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as scio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_path = './'\n",
    "dataset_path =  './Dataset' # Training data\n",
    "\n",
    "classes = ['NSR', 'APB', 'AFL', 'AFIB', 'SVTA', 'WPW','PVC', 'Bigeminy', 'Trigeminy', \n",
    "           'VT', 'IVR', 'VFL', 'Fusion', 'LBBBB', 'RBBBB', 'SDHB', 'PR']\n",
    "ClassesNum = len(classes)\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path, topdown=False):\n",
    "    for name in files:\n",
    "        data_train = scio.loadmat(os.path.join(root, name))# 取出字典里的value\n",
    "        \n",
    "        # arr -> list\n",
    "        data_arr = data_train.get('val')\n",
    "        data_list = data_arr.tolist()\n",
    "        \n",
    "        X.append(data_list[0]) # [[……]] -> [ ]\n",
    "        y.append(int(os.path.basename(root)[0:2]) - 1)  # name -> num\n",
    "        \n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "        \n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "    \n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "X = standardization(X)\n",
    "X = X.reshape((1000,1,3600))\n",
    "y = y.reshape((1000))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"X_train : \", len(X_train))\n",
    "print(\"X_test  : \", len(X_test))\n",
    "print(\"shape of X_train : \", np.shape(X_train[0]))\n",
    "print(\"shape of y_train : \", np.shape(y_train))\n",
    "print(\"shape of X_test : \", np.shape(X_test))\n",
    "print(\"shape of y_test : \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a1fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = X_train.shape[0] # 取第0元素：长度\n",
    "        self.x_train = torch.from_numpy(X_train).float().to(\"cuda\")\n",
    "        self.y_train = torch.from_numpy(y_train).long().to(\"cuda\")\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_train[index], self.y_train[index] # 返回对应样本即可\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = X_test.shape[0] # 取第0元素：长度\n",
    "        self.x_test = torch.from_numpy(X_test).float().to(\"cuda\")\n",
    "        self.y_test = torch.from_numpy(y_test).long().to(\"cuda\")\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_test[index], self.y_test[index] # 返回对应样本即可\n",
    "    def __len__(self):\n",
    "        return self.len    \n",
    "        \n",
    "train_dataset = MyDataset()\n",
    "test_dataset = TestDataset()\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09276fa",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48213bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 8, 1800]             136\n",
      "              ReLU-2              [-1, 8, 1800]               0\n",
      "         MaxPool1d-3               [-1, 8, 449]               0\n",
      "            Conv1d-4              [-1, 12, 224]           1,164\n",
      "              ReLU-5              [-1, 12, 224]               0\n",
      "         MaxPool1d-6              [-1, 12, 111]               0\n",
      "            Conv1d-7              [-1, 32, 111]           3,488\n",
      "              ReLU-8              [-1, 32, 111]               0\n",
      "         MaxPool1d-9               [-1, 32, 54]               0\n",
      "           Conv1d-10               [-1, 64, 54]          14,400\n",
      "             ReLU-11               [-1, 64, 54]               0\n",
      "        MaxPool1d-12               [-1, 64, 26]               0\n",
      "           Conv1d-13               [-1, 64, 26]          20,544\n",
      "             ReLU-14               [-1, 64, 26]               0\n",
      "        MaxPool1d-15               [-1, 64, 13]               0\n",
      "           Conv1d-16               [-1, 64, 13]          12,352\n",
      "             ReLU-17               [-1, 64, 13]               0\n",
      "        MaxPool1d-18                [-1, 64, 6]               0\n",
      "           Conv1d-19                [-1, 72, 6]          13,896\n",
      "             ReLU-20                [-1, 72, 6]               0\n",
      "        MaxPool1d-21                [-1, 72, 3]               0\n",
      "          Flatten-22                  [-1, 216]               0\n",
      "           Linear-23                   [-1, 64]          13,888\n",
      "             ReLU-24                   [-1, 64]               0\n",
      "          Dropout-25                   [-1, 64]               0\n",
      "           Linear-26                   [-1, 17]           1,105\n",
      "================================================================\n",
      "Total params: 80,973\n",
      "Trainable params: 80,973\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.49\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 0.81\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preminstrel/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "in_channels_ = 1\n",
    "num_segments_in_record = 100\n",
    "segment_len = 3600   # 3600 采样\n",
    "num_classes = 17\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n",
    "\n",
    "class arrhythmia_classifier(nn.Module):\n",
    "    def __init__(self, in_channels=in_channels_):\n",
    "        super(arrhythmia_classifier, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1,8,16,stride=2,padding=7),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(8),\n",
    "            nn.MaxPool1d(kernel_size=8,stride=4),\n",
    "   \n",
    "            nn.Conv1d(8,12,12,padding=5,stride=2),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(16),\n",
    "            nn.MaxPool1d(4,stride=2),\n",
    "            \n",
    "            nn.Conv1d(12,32,9,stride=1,padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(5,stride=2),\n",
    "            \n",
    "            nn.Conv1d(32,64,7,stride=1,padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4,stride=2),\n",
    "            \n",
    "            nn.Conv1d(64,64,5,stride=1,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,2),\n",
    "            \n",
    "            nn.Conv1d(64,64,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,2),\n",
    "            \n",
    "            nn.Conv1d(64,72,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,2),\n",
    "            Flatten(),\n",
    "            nn.Linear(in_features=216, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=.1),\n",
    "            nn.Linear(in_features=64, out_features=17),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, ex_features=None):\n",
    "        return self.cnn(x)\n",
    "\n",
    "\n",
    "def calc_next_len_conv1d(current_len=112500, kernel_size=16, stride=8, padding=0, dilation=1):\n",
    "    return int(np.floor((current_len + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = arrhythmia_classifier().to(device)\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 3600))\n",
    "\n",
    "model = torch.load('test_1.pt',map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439fbde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14,  3,  9,  3,  1, 13,  0,  0, 14, 14,  7,  0,  5,  6, 15,  0],\n",
      "       device='cuda:0')\n",
      "tensor([14,  3,  9,  3,  1, 13,  0,  0, 14, 14,  7,  0,  5,  6, 15,  0],\n",
      "       device='cuda:0')\n",
      "tensor([10,  1,  0,  1,  3,  7,  1,  0, 14, 13, 13, 14, 13, 14,  8,  0],\n",
      "       device='cuda:0')\n",
      "tensor([10,  1,  0,  1,  3,  7,  1,  0, 14, 13, 13, 14, 13, 14,  8,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 3,  5,  0,  0, 14,  6,  0, 13,  0, 13,  7,  3, 10, 13, 14,  1],\n",
      "       device='cuda:0')\n",
      "tensor([ 3,  5,  0,  0, 14,  6,  0, 13,  0, 13,  7,  3, 10, 13, 14,  1],\n",
      "       device='cuda:0')\n",
      "tensor([ 2, 12,  3, 10,  0,  3,  7,  6,  0, 14,  3,  9,  3,  0, 13,  3],\n",
      "       device='cuda:0')\n",
      "tensor([ 2, 12,  3, 10,  0,  3,  7,  6,  0, 14,  3,  9,  3,  0, 13,  3],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  8,  3,  6,  6, 13, 14,  3,  0,  6, 15,  7,  0,  7,  1, 13],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  8,  3,  6,  6, 13, 14,  3,  0,  6, 15,  7,  0,  7,  1, 13],\n",
      "       device='cuda:0')\n",
      "tensor([ 3, 14,  3, 14, 16,  2,  3,  6, 16,  5,  6,  7, 13,  2,  3,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 3, 14,  3, 14, 16,  2,  3,  6, 16,  5,  6,  7, 13,  2,  3,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 8, 15,  0,  0,  0,  0,  3, 13,  0,  1, 11, 14, 14,  0,  2,  6],\n",
      "       device='cuda:0')\n",
      "tensor([ 8, 15,  0,  0,  0,  0,  3, 13,  0,  1, 11, 14, 14,  0,  2,  6],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  0,  6,  7, 14, 13,  6,  3, 16,  3,  7,  3,  0,  3, 14,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  0,  6,  7, 14, 13,  6,  3, 16,  3,  7,  3,  0,  3, 14,  0],\n",
      "       device='cuda:0')\n",
      "tensor([13,  0,  6,  2, 16,  7,  1,  3,  3,  1, 12,  6,  0,  6,  6,  0],\n",
      "       device='cuda:0')\n",
      "tensor([13,  0,  6,  2, 16,  7,  1,  3,  3, 14, 12,  6,  0,  6,  6,  0],\n",
      "       device='cuda:0')\n",
      "tensor([14, 13,  0,  2,  4,  3,  6, 16,  6,  0,  1,  3,  0,  6,  8, 13],\n",
      "       device='cuda:0')\n",
      "tensor([14, 13,  0,  2,  4,  3,  6, 16,  6,  0,  1,  3,  0,  6,  8, 13],\n",
      "       device='cuda:0')\n",
      "tensor([ 3,  0,  0, 13, 13,  6, 14,  1,  7, 13,  3,  0,  0,  3,  4,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 3,  0,  0, 13, 13,  6, 14,  1,  7, 13,  3,  0,  0,  3,  4,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 5,  0,  6,  3, 16,  6,  5,  6,  3, 14,  6,  0,  6,  2,  6,  0],\n",
      "       device='cuda:0')\n",
      "tensor([ 5,  0,  6,  3, 16,  6,  5,  6,  3, 14,  6,  0,  6,  2,  6,  0],\n",
      "       device='cuda:0')\n",
      "tensor([0, 6, 6, 1, 0, 7, 6, 3], device='cuda:0')\n",
      "tensor([0, 6, 6, 1, 0, 7, 6, 3], device='cuda:0')\n",
      "Accuracy on test set: 99 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            print(predicted)\n",
    "            print(labels)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "print('Accuracy on test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e4a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "## extra packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "from quant import *\n",
    "from fold_batch_norm import *\n",
    "\n",
    "def mystr2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "## define parser  # 定义程序检查机制\n",
    "parser = argparse.ArgumentParser(description='PyTorch PWLQ code on ECGNet')\n",
    "parser.add_argument('-data', default='/home/preminstrel/ECG-Classification')\n",
    "parser.add_argument('-a', '--arch', default='test_1', help='network architecture')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int)\n",
    "parser.add_argument('-p', '--print-freq', default=100, type=int)\n",
    "parser.add_argument('--gpu', default=None, type=int, help='GPU id to use.')\n",
    "\n",
    "## extras for quantization\n",
    "parser.add_argument('-fbn', '--fold_bn', dest='fold_bn', action='store_true',\n",
    "                    help='fold batch normalization')\n",
    "parser.add_argument('-quant', '--quantize', dest='quantize', action='store_true',\n",
    "                    help='quantize model')\n",
    "parser.add_argument('-gs', '--get_stats', dest='get_stats', action='store_true',\n",
    "                    help='get stats of activations')\n",
    "parser.add_argument('-wb', '--wei_bits', '--weight-bits', default=0.0, type=float,\n",
    "                    metavar='WB', help='weight quantization bits')\n",
    "parser.add_argument('-ab', '--act_bits', '--activation-bits', default=0.0, type=float,\n",
    "                    metavar='AB', help='activation quantization bits')\n",
    "parser.add_argument('-sb', '--scale_bits', default=0.0, type=float,\n",
    "                    metavar='SB', help='scale/shift quantization bits')\n",
    "parser.add_argument('-wq', '--wei_quant_scheme', default='none', type=str,\n",
    "                    choices=['uniform', 'pw-2', 'pw-1'],\n",
    "                    help='weight quantization scheme: uniform, PWLQ')\n",
    "parser.add_argument('-aq', '--act_clip_method', default='top_10', type=str,\n",
    "                    help='activations clip-quantization method'\n",
    "                    'choices: none, on-the-fly, clip_1.0, top_10, etc.')\n",
    "parser.add_argument('-bc', '--bias_corr', default=False, type=mystr2bool,\n",
    "                    help='Whether to use bias correction for weights quantization')\n",
    "parser.add_argument('-appx', '--approximate', default=False, type=mystr2bool,\n",
    "                    help='Whether to use approximated optimal breakpoint')\n",
    "parser.add_argument('-bkp', '--break-point', default='none', type=str,\n",
    "                    help='how to get optimal breakpoint: norm, laplace, search')\n",
    "parser.add_argument('-sr', '--save_res', default=True, type=mystr2bool,\n",
    "                    help='save results')\n",
    "parser.add_argument('-cms', '--comments', default='', type=str,\n",
    "                    help='make comments')\n",
    "\n",
    "## main function\n",
    "def main():\n",
    "    best_acc1 = 0\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    print(str(args))\n",
    "    print()\n",
    "\n",
    "    # use one GPU to get the activation stats \n",
    "    if args.get_stats:\n",
    "        args.gpu = 0\n",
    "        args.batch_size = 4\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        print(\"Use GPU: {} for the calibration of activation ranges\".format(args.gpu))\n",
    "\n",
    "    # load pre-trained model \n",
    "    print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "    model = models.__dict__[args.arch](pretrained=True)\n",
    "    checkpoint = model.state_dict()\n",
    "    print('----- pretrained model loaded -----')\n",
    "\n",
    "    ## fold batch normalization\n",
    "    if args.fold_bn:\n",
    "        checkpoint, weight_layers = fold_batch_norm(checkpoint, arch=args.arch)\n",
    "\n",
    "    # quantize weights\n",
    "    rmse = 0\n",
    "    if args.quantize:\n",
    "        print('quantize weights ...')\n",
    "        assert(args.fold_bn)\n",
    "        checkpoint, rmse = quant_checkpoint(checkpoint, weight_layers, args)\n",
    "    \n",
    "    # load the updated weights\n",
    "    model.load_state_dict(checkpoint)\n",
    "    del checkpoint\n",
    "\n",
    "    # quantize or load activation stats\n",
    "    model = quant_model_acts(model, args.act_bits, args.get_stats, args.batch_size)\n",
    "    if args.quantize and not args.get_stats:\n",
    "        act_stats_save_path = 'stats/%s_act_stats.pth' % args.arch\n",
    "        mode = load_model_act_stats(model, act_stats_save_path, args.act_clip_method)\n",
    "\n",
    "    # use GPU\n",
    "    if args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # load data\n",
    "    crop_size = 224\n",
    "    scale = 0.875\n",
    "    if args.arch.startswith('inception'):\n",
    "        crop_size = 299\n",
    "    large_crop_size = int(round(crop_size / scale))\n",
    "    print('\\nlarger crop size: ', large_crop_size)\n",
    "    print('center crop size: ', crop_size)\n",
    "\n",
    "    traindir = os.path.join(args.data, 'train')\n",
    "    valdir = os.path.join(args.data, 'val')\n",
    "    shuffle_option = False\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    if args.get_stats:\n",
    "        valdir = os.path.join(args.data, 'train')\n",
    "        shuffle_option = True\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(large_crop_size),\n",
    "            transforms.CenterCrop(crop_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=args.batch_size, shuffle=shuffle_option,\n",
    "        num_workers=8, pin_memory=True)\n",
    "    \n",
    "    # get activation stats on training data\n",
    "    if args.get_stats:\n",
    "        # calibrate the activation ranges\n",
    "        validate(val_loader, model, criterion, args)\n",
    "\n",
    "        # save the activation stats\n",
    "        os.makedirs('stats/', exist_ok=True)\n",
    "        act_stats_save_path = 'stats/%s_act_stats.pth' % args.arch\n",
    "        save_model_act_stats(model, act_stats_save_path)\n",
    "\n",
    "        return\n",
    "\n",
    "    # evaluate on validation dataset\n",
    "    val_start_time = time.time()\n",
    "    top1_avg_acc, top5_avg_acc = validate(val_loader, model, criterion, args)\n",
    "    print('\\nvalidation time: %.2f min' % ((time.time() - val_start_time) / 60))\n",
    "\n",
    "    # save accuracy results\n",
    "    save_acc_res = True\n",
    "    save_comments = args.comments \n",
    "    if save_acc_res:\n",
    "        os.makedirs('results/', exist_ok=True)\n",
    "        table_path = 'results/accuracy_results_%s.csv' % args.arch \n",
    "\n",
    "        new_df = pd.DataFrame({'model': [args.arch], 'quantize': [args.quantize], \n",
    "            'wei_bits': [args.wei_bits], 'wei_quant_scheme': [args.wei_quant_scheme],  \n",
    "            'bias_corr': ['BC: yes' if args.bias_corr else 'BC: no'], \n",
    "            'approximate': ['appx: yes' if args.approximate else 'appx: no'], \n",
    "            'scale_bits': [args.scale_bits],\n",
    "            'act_bits': [args.act_bits], 'act_clip_method': [args.act_clip_method],\n",
    "            'break_point': [args.break_point], \n",
    "            'wei_quant_rmse': [rmse], \n",
    "            'top1': [float(top1_avg_acc)], 'top5': [float(top5_avg_acc)], \n",
    "            'comments': [save_comments], \n",
    "            'time': [( datetime.now().strftime('%Y-%m-%d_%H-%M-%S'), \n",
    "                '%.2f min' % ((time.time() - total_start_time)/60) )]})\n",
    "        \n",
    "        new_df = new_df[['model', 'quantize', 'act_bits', 'wei_bits', 'scale_bits', 'act_clip_method', \n",
    "                        'wei_quant_scheme', 'break_point', 'approximate', 'bias_corr',  \n",
    "                        'wei_quant_rmse', 'top1', 'top5', 'time', 'comments']]\n",
    "        \n",
    "        if os.path.exists(table_path):\n",
    "            old_df = pd.read_csv(table_path)\n",
    "            new_df = old_df.append(new_df)\n",
    "        new_df.to_csv(table_path, index = False)\n",
    "        \n",
    "    return\n",
    "\n",
    "# 准确率\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "            if args.get_stats and (i + 1) * args.batch_size >= 512:\n",
    "                break\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg, top5.avg\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b307e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

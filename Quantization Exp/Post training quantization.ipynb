{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bd854e",
   "metadata": {},
   "source": [
    "# Post training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2400f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d0a74",
   "metadata": {},
   "source": [
    "## 量化的基本公式\n",
    " $$S=\\frac{r_{max}-r_{min}}{q_{max}-q_{min}}$$\n",
    " $$Z = round(q_{max}-\\frac{r_{max}}{S})$$\n",
    " $$r=S(q-Z)$$\n",
    " $$q=round(\\frac{r}{S}+Z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489af9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(min_val, max_val, num_bits=8):   # Calculate Zero_Point\n",
    "    qmin = 0.\n",
    "    qmax = 2. ** num_bits - 1.\n",
    "    scale = float((max_val - min_val) / (qmax - qmin)) # S=(rmax-rmin)/(qmax-qmin)\n",
    "\n",
    "    zero_point = qmax - max_val / scale    # Z=round(qmax-rmax/scale)\n",
    "\n",
    "    if zero_point < qmin:\n",
    "        zero_point = qmin\n",
    "    elif zero_point > qmax:\n",
    "        zero_point = qmax\n",
    "    \n",
    "    zero_point = int(zero_point)   # Integer\n",
    "\n",
    "    return scale, zero_point\n",
    "\n",
    "def quantize_tensor(x, scale, zero_point, num_bits=8, signed=False):   # 把tensor quantize\n",
    "    if signed:\n",
    "        qmin = - 2. ** (num_bits - 1)\n",
    "        qmax = 2. ** (num_bits - 1) - 1\n",
    "    else:\n",
    "        qmin = 0.\n",
    "        qmax = 2.**num_bits - 1.\n",
    " \n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()     # q=round(r/S+Z)\n",
    "    \n",
    "    return q_x.float()  # 由于pytorch不支持int类型的运算，因此我们还是用float来表示整数\n",
    "\n",
    "def dequantize_tensor(q_x, scale, zero_point):   # Dequantize\n",
    "    return scale * (q_x - zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0d742",
   "metadata": {},
   "source": [
    "前面提到，在后训练量化过程中，需要先统计样本以及中间层的 min、max，同时也频繁涉及到一些量化、反量化操作，\n",
    "\n",
    "因此我们可以把这些功能都封装成一个 `QParam` 类：update 函数就是用来统计 min、max 的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f08503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QParam:\n",
    "    def __init__(self, num_bits=8):\n",
    "        self.num_bits = num_bits\n",
    "        self.scale = None\n",
    "        self.zero_point = None\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "\n",
    "    def update(self, tensor):\n",
    "        if self.max is None or self.max < tensor.max():\n",
    "            self.max = tensor.max()\n",
    "        self.max = 0 if self.max < 0 else self.max  # 这是什么语法？\n",
    "        \n",
    "        if self.min is None or self.min > tensor.min():\n",
    "            self.min = tensor.min()\n",
    "        self.min = 0 if self.min > 0 else self.min\n",
    "        \n",
    "        self.scale, self.zero_point = calcScaleZeroPoint(self.min, self.max, self.num_bits)\n",
    "    \n",
    "    def quantize_tensor(self, tensor):\n",
    "        return quantize_tensor(tensor, self.scale, self.zero_point, num_bits=self.num_bits)\n",
    "\n",
    "    def dequantize_tensor(self, q_x):\n",
    "        return dequantize_tensor(q_x, self.scale, self.zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38168d1",
   "metadata": {},
   "source": [
    "## 量化网络模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d8af2",
   "metadata": {},
   "source": [
    "下面要来实现一些最基本网络模块的量化形式，包括 *conv、relu、maxpooling* 以及 *fc* 层。\n",
    "\n",
    "首先我们定义一个量化**基类**，这样可以减少一些重复代码，也能让代码结构更加清晰：这个基类规定了每个量化模块都需要提供的方法。\n",
    "\n",
    "`__init__` 函数，除了指定量化的位数外，还需指定是否提供量化输入 (qi) 及输出参数 (qo)。在前面也提到，不是每一个网络模块都需要统计输入的 min、max，大部分中间层都是用上一层的 qo 来作为自己的 qi 的，另外有些中间层的激活函数也是直接用上一层的 qi 来作为自己的 qi 和 qo。\n",
    "\n",
    "其次是 `freeze` 函数，这个函数会在统计完 min、max 后发挥作用。正如上文所说的，公式中有很多项是可以提前计算好的，`freeze` 就是把这些项提前固定下来，同时也将网络的权重由浮点实数转化为定点整数。\n",
    "\n",
    "最后是 `quantize_inference`，这个函数主要是量化 inference 的时候会使用。实际 inference 的时候和正常的 forward 会有一些差异，可以根据之后的代码体会一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6798cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModule(nn.Module):\n",
    "\n",
    "    def __init__(self, qi=True, qo=True, num_bits=8):\n",
    "        super(QModule, self).__init__()\n",
    "        if qi:\n",
    "            self.qi = QParam(num_bits=num_bits)\n",
    "        if qo:\n",
    "            self.qo = QParam(num_bits=num_bits)\n",
    "\n",
    "    def freeze(self):\n",
    "        pass\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        raise NotImplementedError('quantize_inference should be implemented.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d5a70",
   "metadata": {},
   "source": [
    "### 量化卷积层\n",
    "- QConv2d\n",
    "- QLinear\n",
    "- QReLU\n",
    "- QMaxPooling2d\n",
    "- QConvBNReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e840b8",
   "metadata": {},
   "source": [
    "#### QConv2d\n",
    "- 首先是 `__init__` 函数，可以看到我传入了一个 `conv_module` 模块，这个模块对应全精度的卷积层，\n",
    "另外的 qw 参数则是用来统计 weight 的 min、max 以及对 weight 进行量化用的。\n",
    "- 其次是 freeze 函数，这个函数主要就是计算公式中的 $M,q_w$ 以及 $q_b$ 。由于完全实现公式的加速效果需要更底层代码的支持，因此在 pytorch 中我用了更简单的实现方式，即优化前的公式:\n",
    "$$q_a=M(\\sum_i^N (q_w-Z_w)(q_x-Z_x)+q_b)+Z_a$$\n",
    "注意到 freeze 函数可能会传入 qi 或者 qo，这也是之前提到的，有些中间的模块不会有自己的 qi，而是复用之前层的 qo 作为自己的 qi。\n",
    "- 接着是 `forward` 函数，这个函数和正常的 forward 一样，也是在 float 上进行的，只不过需要统计输入输出以及 weight 的 min、max 而已。\n",
    "有读者可能会疑惑为什么需要对 weight 量化到 int8 然后又反量化回 float，这里其实就是所谓的**伪量化节点**，因为我们在实际量化 inference 的时候会把 weight 量化到 int8，这个过程本身是有精度损失的 (来自四舍五入的 round 带来的截断误差)，所以在统计 min、max 的时候，需要把这个过程带来的误差也模拟进去。\n",
    "- 最后是 `quantize_inference` 函数，这个函数在实际 inference 的时候会被调用，对应的就是上面的公式。注意，这个函数里面的卷积操作是在 int 上进行的，这是量化推理加速的关键「当然，由于 pytorch 的限制，我们仍然是在 float 上计算，只不过数值都是整数。这也可以看出量化推理是跟底层实现紧密结合的技术」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6a9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class FakeQuantize(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, qparam):\n",
    "        x = qparam.quantize_tensor(x)\n",
    "        x = qparam.dequantize_tensor(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output, None\n",
    "\n",
    "class QConv2d(QModule):\n",
    "\n",
    "    def __init__(self, conv_module, qi=True, qo=True, num_bits=8):\n",
    "        super(QConv2d, self).__init__(qi=qi, qo=qo, num_bits=num_bits)\n",
    "        self.num_bits = num_bits\n",
    "        self.conv_module = conv_module\n",
    "        self.qw = QParam(num_bits=num_bits)\n",
    "\n",
    "    def freeze(self, qi=None, qo=None):\n",
    "        \n",
    "        if hasattr(self, 'qi') and qi is not None:         # hasattr(object, name)  如果对象有该属性返回 True，否则返回 False。\n",
    "            raise ValueError('qi has been provided in init function.')\n",
    "        if not hasattr(self, 'qi') or qi is None:\n",
    "            raise ValueError('qi is not existed, should be provided.')\n",
    "\n",
    "        if hasattr(self, 'qo') and qo is not None:\n",
    "            raise ValueError('qo has been provided in init function.')\n",
    "        if not hasattr(self, 'qo') or qo is None:\n",
    "            raise ValueError('qo is not existed, should be provided.')\n",
    "\n",
    "        if qi is not None:\n",
    "            self.qi = qi\n",
    "        if qo is not None:\n",
    "            self.qo = qo\n",
    "        self.M = self.qw.scale * self.qi.scale / self.qo.scale  # Calculate M\n",
    "\n",
    "        self.conv_module.weight.data = self.qw.quantize_tensor(self.conv_module.weight.data) # 把权重量化  标准：qw的参数\n",
    "        self.conv_module.weight.data = self.conv_module.weight.data - self.qw.zero_point     # 减去零点\n",
    "\n",
    "        self.conv_module.bias.data = quantize_tensor(self.conv_module.bias.data, scale=self.qi.scale * self.qw.scale,\n",
    "                                                     zero_point=0, num_bits=32, signed=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'qi'):\n",
    "            self.qi.update(x)\n",
    "            x = FakeQuantize.apply(x, self.qi)\n",
    "\n",
    "        self.qw.update(self.conv_module.weight.data)\n",
    "\n",
    "        x = F.conv2d(x, FakeQuantize.apply(self.conv_module.weight, self.qw), self.conv_module.bias, \n",
    "                     stride=self.conv_module.stride,\n",
    "                     padding=self.conv_module.padding, dilation=self.conv_module.dilation, \n",
    "                     groups=self.conv_module.groups)\n",
    "\n",
    "        if hasattr(self, 'qo'):\n",
    "            self.qo.update(x)\n",
    "            x = FakeQuantize.apply(x, self.qo)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        x = x - self.qi.zero_point\n",
    "        x = self.conv_module(x)\n",
    "        x = self.M * x\n",
    "        x.round_() \n",
    "        x = x + self.qo.zero_point        \n",
    "        x.clamp_(0., 2.**self.num_bits-1.).round_()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeff016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear(QModule):\n",
    "\n",
    "    def __init__(self, fc_module, qi=True, qo=True, num_bits=8):\n",
    "        super(QLinear, self).__init__(qi=qi, qo=qo, num_bits=num_bits)\n",
    "        self.num_bits = num_bits\n",
    "        self.fc_module = fc_module\n",
    "        self.qw = QParam(num_bits=num_bits)\n",
    "\n",
    "    def freeze(self, qi=None, qo=None):\n",
    "\n",
    "        if hasattr(self, 'qi') and qi is not None:\n",
    "            raise ValueError('qi has been provided in init function.')\n",
    "        if not hasattr(self, 'qi') and qi is None:\n",
    "            raise ValueError('qi is not existed, should be provided.')\n",
    "\n",
    "        if hasattr(self, 'qo') and qo is not None:\n",
    "            raise ValueError('qo has been provided in init function.')\n",
    "        if not hasattr(self, 'qo') and qo is None:\n",
    "            raise ValueError('qo is not existed, should be provided.')\n",
    "\n",
    "        if qi is not None:\n",
    "            self.qi = qi\n",
    "        if qo is not None:\n",
    "            self.qo = qo\n",
    "        self.M = self.qw.scale * self.qi.scale / self.qo.scale\n",
    "\n",
    "        self.fc_module.weight.data = self.qw.quantize_tensor(self.fc_module.weight.data)\n",
    "        self.fc_module.weight.data = self.fc_module.weight.data - self.qw.zero_point\n",
    "        self.fc_module.bias.data = quantize_tensor(self.fc_module.bias.data, scale=self.qi.scale * self.qw.scale,\n",
    "                                                   zero_point=0, num_bits=32, signed=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'qi'):\n",
    "            self.qi.update(x)\n",
    "            x = FakeQuantize.apply(x, self.qi)\n",
    "\n",
    "        self.qw.update(self.fc_module.weight.data)\n",
    "\n",
    "        x = F.linear(x, FakeQuantize.apply(self.fc_module.weight, self.qw), self.fc_module.bias)\n",
    "\n",
    "        if hasattr(self, 'qo'):\n",
    "            self.qo.update(x)\n",
    "            x = FakeQuantize.apply(x, self.qo)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        x = x - self.qi.zero_point\n",
    "        x = self.fc_module(x)\n",
    "        x = self.M * x\n",
    "        x.round_() \n",
    "        x = x + self.qo.zero_point\n",
    "        x.clamp_(0., 2.**self.num_bits-1.).round_()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4092f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QReLU(QModule):\n",
    "\n",
    "    def __init__(self, qi=False, num_bits=None):\n",
    "        super(QReLU, self).__init__(qi=qi, num_bits=num_bits)\n",
    "\n",
    "    def freeze(self, qi=None):\n",
    "        \n",
    "        if hasattr(self, 'qi') and qi is not None:\n",
    "            raise ValueError('qi has been provided in init function.')\n",
    "        if not hasattr(self, 'qi') and qi is None:\n",
    "            raise ValueError('qi is not existed, should be provided.')\n",
    "\n",
    "        if qi is not None:\n",
    "            self.qi = qi\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'qi'):\n",
    "            self.qi.update(x)\n",
    "            x = FakeQuantize.apply(x, self.qi)\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def quantize_inference(self, x):\n",
    "        x = x.clone()\n",
    "        x[x < self.qi.zero_point] = self.qi.zero_point\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771eaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMaxPooling2d(QModule):\n",
    "\n",
    "    def __init__(self, kernel_size=2, stride=2, padding=0, qi=False, num_bits=None):\n",
    "        super(QMaxPooling2d, self).__init__(qi=qi, num_bits=num_bits)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def freeze(self, qi=None):\n",
    "        if hasattr(self, 'qi') and qi is not None:\n",
    "            raise ValueError('qi has been provided in init function.')\n",
    "        if not hasattr(self, 'qi') and qi is None:\n",
    "            raise ValueError('qi is not existed, should be provided.')\n",
    "        if qi is None:\n",
    "            self.qi = qi\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'qi'):\n",
    "            self.qi.update(x)\n",
    "            x = FakeQuantize.apply(x, self.qi)\n",
    "\n",
    "        x = F.max_pool2d(x, self.kernel_size, self.stride, self.padding)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        return F.max_pool2d(x, self.kernel_size, self.stride, self.padding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ef923",
   "metadata": {},
   "source": [
    "## Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851ed52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = nn.Sequential(OrderedDict([\n",
    "            ('conv1',nn.Conv2d(1, 16, kernel_size=3, stride=1,padding=1)),\n",
    "            ('relu1',nn.ReLU()),\n",
    "            ('max1',nn.MaxPool2d(2)),\n",
    "            ('conv2',nn.Conv2d(16, 32, kernel_size=3, stride=1,padding=1)),\n",
    "            ('relu2',nn.ReLU()),\n",
    "            ('max2',nn.MaxPool2d(2)),\n",
    "            ('Flat',nn.Flatten()),\n",
    "            ('Softmax',nn.Linear(32*7*7, 10))\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "    def quantize(self, num_bits=8):\n",
    "        self.qconv1 = QConv2d(self.cnn[0], qi=True, qo=True, num_bits=num_bits)\n",
    "        self.qrelu1 = QReLU()\n",
    "        self.qmaxpool2d_1 = QMaxPooling2d(kernel_size=2, stride=0, padding=0)\n",
    "        self.qconv2 = QConv2d(self.cnn[3], qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qrelu2 = QReLU()\n",
    "        self.qmaxpool2d_2 = QMaxPooling2d(kernel_size=2, stride=0, padding=0)\n",
    "        self.qfc = QLinear(self.cnn[7], qi=False, qo=True, num_bits=num_bits)\n",
    "\n",
    "    def quantize_forward(self, x):\n",
    "        x = self.qconv1(x)\n",
    "        x = self.qrelu1(x)\n",
    "        x = self.qmaxpool2d_1(x)\n",
    "        x = self.qconv2(x)\n",
    "        x = self.qrelu2(x)\n",
    "        x = self.qmaxpool2d_2(x)\n",
    "        x = x.view(-1, 32*7*7)\n",
    "        x = self.qfc(x)\n",
    "        return x\n",
    "\n",
    "    def freeze(self):\n",
    "        self.qconv1.freeze()\n",
    "        self.qrelu1.freeze(self.qconv1.qo)\n",
    "        self.qmaxpool2d_1.freeze(self.qconv1.qo)\n",
    "        self.qconv2.freeze(qi=self.qconv1.qo)\n",
    "        self.qrelu2.freeze(self.qconv2.qo)\n",
    "        self.qmaxpool2d_2.freeze(self.qconv2.qo)\n",
    "        self.qfc.freeze(qi=self.qconv2.qo)\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        qx = self.qconv1.qi.quantize_tensor(x)\n",
    "        qx = self.qconv1.quantize_inference(qx)\n",
    "        qx = self.qrelu1.quantize_inference(qx)\n",
    "        qx = self.qmaxpool2d_1.quantize_inference(qx)\n",
    "        qx = self.qconv2.quantize_inference(qx)\n",
    "        qx = self.qrelu2.quantize_inference(qx)\n",
    "        qx = self.qmaxpool2d_2.quantize_inference(qx)\n",
    "        qx = qx.view(-1, 32*7*7)\n",
    "        qx = self.qfc.quantize_inference(qx)\n",
    "        out = self.qfc.qo.dequantize_tensor(qx)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db622565",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac5c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preminstrel/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=True, download=True, \n",
    "                 transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                 ])),\n",
    "  batch_size=64, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "  ])),\n",
    "  batch_size=64, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a2f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "                        Kernel Shape     Output Shape  Params Mult-Adds\n",
      "Layer                                                                  \n",
      "0_cnn.Conv2d_conv1     [1, 16, 3, 3]  [1, 16, 28, 28]   160.0  112.896k\n",
      "1_cnn.ReLU_relu1                   -  [1, 16, 28, 28]       -         -\n",
      "2_cnn.MaxPool2d_max1               -  [1, 16, 14, 14]       -         -\n",
      "3_cnn.Conv2d_conv2    [16, 32, 3, 3]  [1, 32, 14, 14]   4.64k  903.168k\n",
      "4_cnn.ReLU_relu2                   -  [1, 32, 14, 14]       -         -\n",
      "5_cnn.MaxPool2d_max2               -    [1, 32, 7, 7]       -         -\n",
      "6_cnn.Flatten_Flat                 -        [1, 1568]       -         -\n",
      "7_cnn.Linear_Softmax      [1568, 10]          [1, 10]  15.69k    15.68k\n",
      "-------------------------------------------------------------------------\n",
      "                         Totals\n",
      "Total params             20.49k\n",
      "Trainable params         20.49k\n",
      "Non-trainable params        0.0\n",
      "Mult-Adds             1.031744M\n",
      "=========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preminstrel/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/preminstrel/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_cnn.Conv2d_conv1</th>\n",
       "      <td>[1, 16, 3, 3]</td>\n",
       "      <td>[1, 16, 28, 28]</td>\n",
       "      <td>160.0</td>\n",
       "      <td>112896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_cnn.ReLU_relu1</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16, 28, 28]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_cnn.MaxPool2d_max1</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_cnn.Conv2d_conv2</th>\n",
       "      <td>[16, 32, 3, 3]</td>\n",
       "      <td>[1, 32, 14, 14]</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>903168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_cnn.ReLU_relu2</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_cnn.MaxPool2d_max2</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 7, 7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_cnn.Flatten_Flat</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 1568]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_cnn.Linear_Softmax</th>\n",
       "      <td>[1568, 10]</td>\n",
       "      <td>[1, 10]</td>\n",
       "      <td>15690.0</td>\n",
       "      <td>15680.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Kernel Shape     Output Shape   Params  Mult-Adds\n",
       "Layer                                                                    \n",
       "0_cnn.Conv2d_conv1     [1, 16, 3, 3]  [1, 16, 28, 28]    160.0   112896.0\n",
       "1_cnn.ReLU_relu1                   -  [1, 16, 28, 28]      NaN        NaN\n",
       "2_cnn.MaxPool2d_max1               -  [1, 16, 14, 14]      NaN        NaN\n",
       "3_cnn.Conv2d_conv2    [16, 32, 3, 3]  [1, 32, 14, 14]   4640.0   903168.0\n",
       "4_cnn.ReLU_relu2                   -  [1, 32, 14, 14]      NaN        NaN\n",
       "5_cnn.MaxPool2d_max2               -    [1, 32, 7, 7]      NaN        NaN\n",
       "6_cnn.Flatten_Flat                 -        [1, 1568]      NaN        NaN\n",
       "7_cnn.Linear_Softmax      [1568, 10]          [1, 10]  15690.0    15680.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "summary(Net(),torch.zeros(1,1,28,28).to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9578f756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn): Sequential(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (max2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (Flat): Flatten(start_dim=1, end_dim=-1)\n",
      "    (Softmax): Linear(in_features=1568, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e28e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cnn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1839af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000]\tLoss: 2.306624\n",
      "Train Epoch: 1 [3200/60000]\tLoss: 0.759732\n",
      "Train Epoch: 1 [6400/60000]\tLoss: 0.558619\n",
      "Train Epoch: 1 [9600/60000]\tLoss: 0.530320\n",
      "Train Epoch: 1 [12800/60000]\tLoss: 0.356621\n",
      "Train Epoch: 1 [16000/60000]\tLoss: 0.214483\n",
      "Train Epoch: 1 [19200/60000]\tLoss: 0.208317\n",
      "Train Epoch: 1 [22400/60000]\tLoss: 0.286776\n",
      "Train Epoch: 1 [25600/60000]\tLoss: 0.156135\n",
      "Train Epoch: 1 [28800/60000]\tLoss: 0.135184\n",
      "Train Epoch: 1 [32000/60000]\tLoss: 0.172798\n",
      "Train Epoch: 1 [35200/60000]\tLoss: 0.161894\n",
      "Train Epoch: 1 [38400/60000]\tLoss: 0.125891\n",
      "Train Epoch: 1 [41600/60000]\tLoss: 0.163238\n",
      "Train Epoch: 1 [44800/60000]\tLoss: 0.094096\n",
      "Train Epoch: 1 [48000/60000]\tLoss: 0.190847\n",
      "Train Epoch: 1 [51200/60000]\tLoss: 0.110937\n",
      "Train Epoch: 1 [54400/60000]\tLoss: 0.124313\n",
      "Train Epoch: 1 [57600/60000]\tLoss: 0.117271\n",
      "\n",
      "Test set: Average loss: 0.1254, Accuracy: 96%\n",
      "\n",
      "Train Epoch: 2 [0/60000]\tLoss: 0.053423\n",
      "Train Epoch: 2 [3200/60000]\tLoss: 0.141812\n",
      "Train Epoch: 2 [6400/60000]\tLoss: 0.238737\n",
      "Train Epoch: 2 [9600/60000]\tLoss: 0.262248\n",
      "Train Epoch: 2 [12800/60000]\tLoss: 0.060289\n",
      "Train Epoch: 2 [16000/60000]\tLoss: 0.226586\n",
      "Train Epoch: 2 [19200/60000]\tLoss: 0.099950\n",
      "Train Epoch: 2 [22400/60000]\tLoss: 0.023910\n",
      "Train Epoch: 2 [25600/60000]\tLoss: 0.041877\n",
      "Train Epoch: 2 [28800/60000]\tLoss: 0.046273\n",
      "Train Epoch: 2 [32000/60000]\tLoss: 0.137283\n",
      "Train Epoch: 2 [35200/60000]\tLoss: 0.165368\n",
      "Train Epoch: 2 [38400/60000]\tLoss: 0.132965\n",
      "Train Epoch: 2 [41600/60000]\tLoss: 0.023957\n",
      "Train Epoch: 2 [44800/60000]\tLoss: 0.072595\n",
      "Train Epoch: 2 [48000/60000]\tLoss: 0.035770\n",
      "Train Epoch: 2 [51200/60000]\tLoss: 0.113612\n",
      "Train Epoch: 2 [54400/60000]\tLoss: 0.077137\n",
      "Train Epoch: 2 [57600/60000]\tLoss: 0.042579\n",
      "\n",
      "Test set: Average loss: 0.0785, Accuracy: 98%\n",
      "\n",
      "Train Epoch: 3 [0/60000]\tLoss: 0.138449\n",
      "Train Epoch: 3 [3200/60000]\tLoss: 0.116326\n",
      "Train Epoch: 3 [6400/60000]\tLoss: 0.238159\n",
      "Train Epoch: 3 [9600/60000]\tLoss: 0.090109\n",
      "Train Epoch: 3 [12800/60000]\tLoss: 0.037785\n",
      "Train Epoch: 3 [16000/60000]\tLoss: 0.057217\n",
      "Train Epoch: 3 [19200/60000]\tLoss: 0.137462\n",
      "Train Epoch: 3 [22400/60000]\tLoss: 0.115106\n",
      "Train Epoch: 3 [25600/60000]\tLoss: 0.157530\n",
      "Train Epoch: 3 [28800/60000]\tLoss: 0.022070\n",
      "Train Epoch: 3 [32000/60000]\tLoss: 0.164767\n",
      "Train Epoch: 3 [35200/60000]\tLoss: 0.097978\n",
      "Train Epoch: 3 [38400/60000]\tLoss: 0.085602\n",
      "Train Epoch: 3 [41600/60000]\tLoss: 0.059795\n",
      "Train Epoch: 3 [44800/60000]\tLoss: 0.033606\n",
      "Train Epoch: 3 [48000/60000]\tLoss: 0.198942\n",
      "Train Epoch: 3 [51200/60000]\tLoss: 0.007820\n",
      "Train Epoch: 3 [54400/60000]\tLoss: 0.131526\n",
      "Train Epoch: 3 [57600/60000]\tLoss: 0.033079\n",
      "\n",
      "Test set: Average loss: 0.0567, Accuracy: 98%\n",
      "\n",
      "Train Epoch: 4 [0/60000]\tLoss: 0.060908\n",
      "Train Epoch: 4 [3200/60000]\tLoss: 0.034881\n",
      "Train Epoch: 4 [6400/60000]\tLoss: 0.122422\n",
      "Train Epoch: 4 [9600/60000]\tLoss: 0.205743\n",
      "Train Epoch: 4 [12800/60000]\tLoss: 0.081357\n",
      "Train Epoch: 4 [16000/60000]\tLoss: 0.057831\n",
      "Train Epoch: 4 [19200/60000]\tLoss: 0.036419\n",
      "Train Epoch: 4 [22400/60000]\tLoss: 0.083942\n",
      "Train Epoch: 4 [25600/60000]\tLoss: 0.244716\n",
      "Train Epoch: 4 [28800/60000]\tLoss: 0.059793\n",
      "Train Epoch: 4 [32000/60000]\tLoss: 0.019686\n",
      "Train Epoch: 4 [35200/60000]\tLoss: 0.048703\n",
      "Train Epoch: 4 [38400/60000]\tLoss: 0.062493\n",
      "Train Epoch: 4 [41600/60000]\tLoss: 0.019459\n",
      "Train Epoch: 4 [44800/60000]\tLoss: 0.014431\n",
      "Train Epoch: 4 [48000/60000]\tLoss: 0.029218\n",
      "Train Epoch: 4 [51200/60000]\tLoss: 0.072483\n",
      "Train Epoch: 4 [54400/60000]\tLoss: 0.079649\n",
      "Train Epoch: 4 [57600/60000]\tLoss: 0.043834\n",
      "\n",
      "Test set: Average loss: 0.0519, Accuracy: 98%\n",
      "\n",
      "Train Epoch: 5 [0/60000]\tLoss: 0.066410\n",
      "Train Epoch: 5 [3200/60000]\tLoss: 0.017825\n",
      "Train Epoch: 5 [6400/60000]\tLoss: 0.044469\n",
      "Train Epoch: 5 [9600/60000]\tLoss: 0.116033\n",
      "Train Epoch: 5 [12800/60000]\tLoss: 0.080438\n",
      "Train Epoch: 5 [16000/60000]\tLoss: 0.007216\n",
      "Train Epoch: 5 [19200/60000]\tLoss: 0.069059\n",
      "Train Epoch: 5 [22400/60000]\tLoss: 0.074849\n",
      "Train Epoch: 5 [25600/60000]\tLoss: 0.013500\n",
      "Train Epoch: 5 [28800/60000]\tLoss: 0.092752\n",
      "Train Epoch: 5 [32000/60000]\tLoss: 0.030570\n",
      "Train Epoch: 5 [35200/60000]\tLoss: 0.020000\n",
      "Train Epoch: 5 [38400/60000]\tLoss: 0.054019\n",
      "Train Epoch: 5 [41600/60000]\tLoss: 0.233620\n",
      "Train Epoch: 5 [44800/60000]\tLoss: 0.091666\n",
      "Train Epoch: 5 [48000/60000]\tLoss: 0.006733\n",
      "Train Epoch: 5 [51200/60000]\tLoss: 0.071692\n",
      "Train Epoch: 5 [54400/60000]\tLoss: 0.033844\n",
      "Train Epoch: 5 [57600/60000]\tLoss: 0.010363\n",
      "\n",
      "Test set: Average loss: 0.0523, Accuracy: 98%\n",
      "\n",
      "Train Epoch: 6 [0/60000]\tLoss: 0.106154\n",
      "Train Epoch: 6 [3200/60000]\tLoss: 0.023358\n",
      "Train Epoch: 6 [6400/60000]\tLoss: 0.033550\n",
      "Train Epoch: 6 [9600/60000]\tLoss: 0.022562\n",
      "Train Epoch: 6 [12800/60000]\tLoss: 0.054433\n",
      "Train Epoch: 6 [16000/60000]\tLoss: 0.023257\n",
      "Train Epoch: 6 [19200/60000]\tLoss: 0.045700\n",
      "Train Epoch: 6 [22400/60000]\tLoss: 0.062430\n",
      "Train Epoch: 6 [25600/60000]\tLoss: 0.045930\n",
      "Train Epoch: 6 [28800/60000]\tLoss: 0.034988\n",
      "Train Epoch: 6 [32000/60000]\tLoss: 0.043221\n",
      "Train Epoch: 6 [35200/60000]\tLoss: 0.139110\n",
      "Train Epoch: 6 [38400/60000]\tLoss: 0.015177\n",
      "Train Epoch: 6 [41600/60000]\tLoss: 0.085878\n",
      "Train Epoch: 6 [44800/60000]\tLoss: 0.042416\n",
      "Train Epoch: 6 [48000/60000]\tLoss: 0.075350\n",
      "Train Epoch: 6 [51200/60000]\tLoss: 0.019317\n",
      "Train Epoch: 6 [54400/60000]\tLoss: 0.016197\n",
      "Train Epoch: 6 [57600/60000]\tLoss: 0.077502\n",
      "\n",
      "Test set: Average loss: 0.0410, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 7 [0/60000]\tLoss: 0.169179\n",
      "Train Epoch: 7 [3200/60000]\tLoss: 0.091602\n",
      "Train Epoch: 7 [6400/60000]\tLoss: 0.050659\n",
      "Train Epoch: 7 [9600/60000]\tLoss: 0.090887\n",
      "Train Epoch: 7 [12800/60000]\tLoss: 0.030627\n",
      "Train Epoch: 7 [16000/60000]\tLoss: 0.047467\n",
      "Train Epoch: 7 [19200/60000]\tLoss: 0.082982\n",
      "Train Epoch: 7 [22400/60000]\tLoss: 0.098623\n",
      "Train Epoch: 7 [25600/60000]\tLoss: 0.050936\n",
      "Train Epoch: 7 [28800/60000]\tLoss: 0.034254\n",
      "Train Epoch: 7 [32000/60000]\tLoss: 0.005246\n",
      "Train Epoch: 7 [35200/60000]\tLoss: 0.230649\n",
      "Train Epoch: 7 [38400/60000]\tLoss: 0.041058\n",
      "Train Epoch: 7 [41600/60000]\tLoss: 0.008099\n",
      "Train Epoch: 7 [44800/60000]\tLoss: 0.010118\n",
      "Train Epoch: 7 [48000/60000]\tLoss: 0.046796\n",
      "Train Epoch: 7 [51200/60000]\tLoss: 0.040202\n",
      "Train Epoch: 7 [54400/60000]\tLoss: 0.008568\n",
      "Train Epoch: 7 [57600/60000]\tLoss: 0.038594\n",
      "\n",
      "Test set: Average loss: 0.0396, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 8 [0/60000]\tLoss: 0.025936\n",
      "Train Epoch: 8 [3200/60000]\tLoss: 0.030525\n",
      "Train Epoch: 8 [6400/60000]\tLoss: 0.030847\n",
      "Train Epoch: 8 [9600/60000]\tLoss: 0.022428\n",
      "Train Epoch: 8 [12800/60000]\tLoss: 0.009997\n",
      "Train Epoch: 8 [16000/60000]\tLoss: 0.019618\n",
      "Train Epoch: 8 [19200/60000]\tLoss: 0.086034\n",
      "Train Epoch: 8 [22400/60000]\tLoss: 0.005126\n",
      "Train Epoch: 8 [25600/60000]\tLoss: 0.100334\n",
      "Train Epoch: 8 [28800/60000]\tLoss: 0.002462\n",
      "Train Epoch: 8 [32000/60000]\tLoss: 0.036736\n",
      "Train Epoch: 8 [35200/60000]\tLoss: 0.014415\n",
      "Train Epoch: 8 [38400/60000]\tLoss: 0.038539\n",
      "Train Epoch: 8 [41600/60000]\tLoss: 0.044085\n",
      "Train Epoch: 8 [44800/60000]\tLoss: 0.024389\n",
      "Train Epoch: 8 [48000/60000]\tLoss: 0.028126\n",
      "Train Epoch: 8 [51200/60000]\tLoss: 0.015068\n",
      "Train Epoch: 8 [54400/60000]\tLoss: 0.015449\n",
      "Train Epoch: 8 [57600/60000]\tLoss: 0.019276\n",
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 98%\n",
      "\n",
      "Train Epoch: 9 [0/60000]\tLoss: 0.008736\n",
      "Train Epoch: 9 [3200/60000]\tLoss: 0.058589\n",
      "Train Epoch: 9 [6400/60000]\tLoss: 0.082234\n",
      "Train Epoch: 9 [9600/60000]\tLoss: 0.091216\n",
      "Train Epoch: 9 [12800/60000]\tLoss: 0.011391\n",
      "Train Epoch: 9 [16000/60000]\tLoss: 0.026285\n",
      "Train Epoch: 9 [19200/60000]\tLoss: 0.036977\n",
      "Train Epoch: 9 [22400/60000]\tLoss: 0.072140\n",
      "Train Epoch: 9 [25600/60000]\tLoss: 0.035931\n",
      "Train Epoch: 9 [28800/60000]\tLoss: 0.008243\n",
      "Train Epoch: 9 [32000/60000]\tLoss: 0.019029\n",
      "Train Epoch: 9 [35200/60000]\tLoss: 0.032407\n",
      "Train Epoch: 9 [38400/60000]\tLoss: 0.012178\n",
      "Train Epoch: 9 [41600/60000]\tLoss: 0.080106\n",
      "Train Epoch: 9 [44800/60000]\tLoss: 0.007267\n",
      "Train Epoch: 9 [48000/60000]\tLoss: 0.113989\n",
      "Train Epoch: 9 [51200/60000]\tLoss: 0.026948\n",
      "Train Epoch: 9 [54400/60000]\tLoss: 0.060108\n",
      "Train Epoch: 9 [57600/60000]\tLoss: 0.013085\n",
      "\n",
      "Test set: Average loss: 0.0409, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 10 [0/60000]\tLoss: 0.022484\n",
      "Train Epoch: 10 [3200/60000]\tLoss: 0.005452\n",
      "Train Epoch: 10 [6400/60000]\tLoss: 0.043277\n",
      "Train Epoch: 10 [9600/60000]\tLoss: 0.017879\n",
      "Train Epoch: 10 [12800/60000]\tLoss: 0.097013\n",
      "Train Epoch: 10 [16000/60000]\tLoss: 0.029281\n",
      "Train Epoch: 10 [19200/60000]\tLoss: 0.175735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [22400/60000]\tLoss: 0.065324\n",
      "Train Epoch: 10 [25600/60000]\tLoss: 0.043995\n",
      "Train Epoch: 10 [28800/60000]\tLoss: 0.020818\n",
      "Train Epoch: 10 [32000/60000]\tLoss: 0.084497\n",
      "Train Epoch: 10 [35200/60000]\tLoss: 0.037622\n",
      "Train Epoch: 10 [38400/60000]\tLoss: 0.005648\n",
      "Train Epoch: 10 [41600/60000]\tLoss: 0.087433\n",
      "Train Epoch: 10 [44800/60000]\tLoss: 0.055323\n",
      "Train Epoch: 10 [48000/60000]\tLoss: 0.142046\n",
      "Train Epoch: 10 [51200/60000]\tLoss: 0.014084\n",
      "Train Epoch: 10 [54400/60000]\tLoss: 0.013668\n",
      "Train Epoch: 10 [57600/60000]\tLoss: 0.010178\n",
      "\n",
      "Test set: Average loss: 0.0365, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 11 [0/60000]\tLoss: 0.022897\n",
      "Train Epoch: 11 [3200/60000]\tLoss: 0.020405\n",
      "Train Epoch: 11 [6400/60000]\tLoss: 0.002943\n",
      "Train Epoch: 11 [9600/60000]\tLoss: 0.001846\n",
      "Train Epoch: 11 [12800/60000]\tLoss: 0.034315\n",
      "Train Epoch: 11 [16000/60000]\tLoss: 0.033893\n",
      "Train Epoch: 11 [19200/60000]\tLoss: 0.004896\n",
      "Train Epoch: 11 [22400/60000]\tLoss: 0.013451\n",
      "Train Epoch: 11 [25600/60000]\tLoss: 0.053857\n",
      "Train Epoch: 11 [28800/60000]\tLoss: 0.011654\n",
      "Train Epoch: 11 [32000/60000]\tLoss: 0.033568\n",
      "Train Epoch: 11 [35200/60000]\tLoss: 0.011570\n",
      "Train Epoch: 11 [38400/60000]\tLoss: 0.067045\n",
      "Train Epoch: 11 [41600/60000]\tLoss: 0.027164\n",
      "Train Epoch: 11 [44800/60000]\tLoss: 0.049992\n",
      "Train Epoch: 11 [48000/60000]\tLoss: 0.028994\n",
      "Train Epoch: 11 [51200/60000]\tLoss: 0.066676\n",
      "Train Epoch: 11 [54400/60000]\tLoss: 0.004595\n",
      "Train Epoch: 11 [57600/60000]\tLoss: 0.045999\n",
      "\n",
      "Test set: Average loss: 0.0377, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 12 [0/60000]\tLoss: 0.008622\n",
      "Train Epoch: 12 [3200/60000]\tLoss: 0.034332\n",
      "Train Epoch: 12 [6400/60000]\tLoss: 0.029938\n",
      "Train Epoch: 12 [9600/60000]\tLoss: 0.007514\n",
      "Train Epoch: 12 [12800/60000]\tLoss: 0.010667\n",
      "Train Epoch: 12 [16000/60000]\tLoss: 0.001418\n",
      "Train Epoch: 12 [19200/60000]\tLoss: 0.015713\n",
      "Train Epoch: 12 [22400/60000]\tLoss: 0.180589\n",
      "Train Epoch: 12 [25600/60000]\tLoss: 0.012520\n",
      "Train Epoch: 12 [28800/60000]\tLoss: 0.017500\n",
      "Train Epoch: 12 [32000/60000]\tLoss: 0.003661\n",
      "Train Epoch: 12 [35200/60000]\tLoss: 0.029290\n",
      "Train Epoch: 12 [38400/60000]\tLoss: 0.003864\n",
      "Train Epoch: 12 [41600/60000]\tLoss: 0.015309\n",
      "Train Epoch: 12 [44800/60000]\tLoss: 0.091642\n",
      "Train Epoch: 12 [48000/60000]\tLoss: 0.041823\n",
      "Train Epoch: 12 [51200/60000]\tLoss: 0.016912\n",
      "Train Epoch: 12 [54400/60000]\tLoss: 0.042105\n",
      "Train Epoch: 12 [57600/60000]\tLoss: 0.076993\n",
      "\n",
      "Test set: Average loss: 0.0389, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 13 [0/60000]\tLoss: 0.036234\n",
      "Train Epoch: 13 [3200/60000]\tLoss: 0.019282\n",
      "Train Epoch: 13 [6400/60000]\tLoss: 0.004898\n",
      "Train Epoch: 13 [9600/60000]\tLoss: 0.004749\n",
      "Train Epoch: 13 [12800/60000]\tLoss: 0.057517\n",
      "Train Epoch: 13 [16000/60000]\tLoss: 0.010540\n",
      "Train Epoch: 13 [19200/60000]\tLoss: 0.006840\n",
      "Train Epoch: 13 [22400/60000]\tLoss: 0.039306\n",
      "Train Epoch: 13 [25600/60000]\tLoss: 0.018801\n",
      "Train Epoch: 13 [28800/60000]\tLoss: 0.014830\n",
      "Train Epoch: 13 [32000/60000]\tLoss: 0.045742\n",
      "Train Epoch: 13 [35200/60000]\tLoss: 0.008864\n",
      "Train Epoch: 13 [38400/60000]\tLoss: 0.012087\n",
      "Train Epoch: 13 [41600/60000]\tLoss: 0.094975\n",
      "Train Epoch: 13 [44800/60000]\tLoss: 0.028078\n",
      "Train Epoch: 13 [48000/60000]\tLoss: 0.046593\n",
      "Train Epoch: 13 [51200/60000]\tLoss: 0.003633\n",
      "Train Epoch: 13 [54400/60000]\tLoss: 0.003910\n",
      "Train Epoch: 13 [57600/60000]\tLoss: 0.018124\n",
      "\n",
      "Test set: Average loss: 0.0431, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 14 [0/60000]\tLoss: 0.044365\n",
      "Train Epoch: 14 [3200/60000]\tLoss: 0.041200\n",
      "Train Epoch: 14 [6400/60000]\tLoss: 0.025426\n",
      "Train Epoch: 14 [9600/60000]\tLoss: 0.005640\n",
      "Train Epoch: 14 [12800/60000]\tLoss: 0.011433\n",
      "Train Epoch: 14 [16000/60000]\tLoss: 0.015999\n",
      "Train Epoch: 14 [19200/60000]\tLoss: 0.012191\n",
      "Train Epoch: 14 [22400/60000]\tLoss: 0.376979\n",
      "Train Epoch: 14 [25600/60000]\tLoss: 0.017698\n",
      "Train Epoch: 14 [28800/60000]\tLoss: 0.007081\n",
      "Train Epoch: 14 [32000/60000]\tLoss: 0.010745\n",
      "Train Epoch: 14 [35200/60000]\tLoss: 0.001195\n",
      "Train Epoch: 14 [38400/60000]\tLoss: 0.039155\n",
      "Train Epoch: 14 [41600/60000]\tLoss: 0.004694\n",
      "Train Epoch: 14 [44800/60000]\tLoss: 0.043182\n",
      "Train Epoch: 14 [48000/60000]\tLoss: 0.011215\n",
      "Train Epoch: 14 [51200/60000]\tLoss: 0.051919\n",
      "Train Epoch: 14 [54400/60000]\tLoss: 0.027662\n",
      "Train Epoch: 14 [57600/60000]\tLoss: 0.015862\n",
      "\n",
      "Test set: Average loss: 0.0363, Accuracy: 99%\n",
      "\n",
      "Train Epoch: 15 [0/60000]\tLoss: 0.095414\n",
      "Train Epoch: 15 [3200/60000]\tLoss: 0.009359\n",
      "Train Epoch: 15 [6400/60000]\tLoss: 0.008163\n",
      "Train Epoch: 15 [9600/60000]\tLoss: 0.030516\n",
      "Train Epoch: 15 [12800/60000]\tLoss: 0.008111\n",
      "Train Epoch: 15 [16000/60000]\tLoss: 0.035507\n",
      "Train Epoch: 15 [19200/60000]\tLoss: 0.000775\n",
      "Train Epoch: 15 [22400/60000]\tLoss: 0.068660\n",
      "Train Epoch: 15 [25600/60000]\tLoss: 0.007991\n",
      "Train Epoch: 15 [28800/60000]\tLoss: 0.001119\n",
      "Train Epoch: 15 [32000/60000]\tLoss: 0.079085\n",
      "Train Epoch: 15 [35200/60000]\tLoss: 0.007298\n",
      "Train Epoch: 15 [38400/60000]\tLoss: 0.047990\n",
      "Train Epoch: 15 [41600/60000]\tLoss: 0.016644\n",
      "Train Epoch: 15 [44800/60000]\tLoss: 0.017691\n",
      "Train Epoch: 15 [48000/60000]\tLoss: 0.002985\n",
      "Train Epoch: 15 [51200/60000]\tLoss: 0.017970\n",
      "Train Epoch: 15 [54400/60000]\tLoss: 0.013499\n",
      "Train Epoch: 15 [57600/60000]\tLoss: 0.001325\n",
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 99%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    lossLayer = torch.nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = lossLayer(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()\n",
    "            ))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += lossLayer(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\n",
    "        test_loss, 100. * correct / len(test_loader.dataset)\n",
    "    ))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    seed = 1\n",
    "    epochs = 15\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    save_model = True\n",
    "    using_bn = False\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if using_bn:\n",
    "        model = NetBN().to(device)\n",
    "    else:\n",
    "        model = Net().to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "    \n",
    "\n",
    "    torch.save(model.state_dict(), './mnist_cnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617630b",
   "metadata": {},
   "source": [
    "## 后训练量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c84a55b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "qi is not existed, should be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_856/3881344986.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'direct quantization finish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquantize_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_856/2885257436.py\u001b[0m in \u001b[0;36mfreeze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqrelu1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqmaxpool2d_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_856/1429268608.py\u001b[0m in \u001b[0;36mfreeze\u001b[0;34m(self, qi, qo)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qi has been provided in init function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qi'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mqi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qi is not existed, should be provided.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qo'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: qi is not existed, should be provided."
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('./mnist_cnn.pt'))\n",
    "model.quantize(num_bits=8)\n",
    "\n",
    "def direct_quantize(model, test_loader):\n",
    "    for i, (data, target) in enumerate(test_loader, 1):\n",
    "        output = model.quantize_forward(data)\n",
    "        if i % 200 == 0:\n",
    "            break\n",
    "    print('direct quantization finish')\n",
    "    \n",
    "model.freeze()\n",
    "\n",
    "def quantize_inference(model, test_loader):\n",
    "    correct = 0\n",
    "    for i, (data, target) in enumerate(test_loader, 1):\n",
    "        output = model.quantize_inference(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('\\nTest set: Quant Model Accuracy: {:.0f}%\\n'.format(100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "quantize_inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "db2adf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConv2d(\n",
       "  (conv_module): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.qconv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5902cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ori_model***\n",
      " LeNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "\n",
      "***quant_model_wbwtab***\n",
      " QuantLeNetWbWtAb(\n",
      "  (conv1): QuantConv2d(\n",
      "    1, 10, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (weight_quantizer): WeightQuantizer()\n",
      "  )\n",
      "  (conv2): QuantConv2d(\n",
      "    10, 20, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (weight_quantizer): WeightQuantizer()\n",
      "  )\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ActivationQuantizer(\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "***quant_model_dorefa***\n",
      " QuantLeNetDoReFa(\n",
      "  (conv1): QuantConv2d(\n",
      "    1, 10, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (activation_quantizer): ActivationQuantizer()\n",
      "    (weight_quantizer): WeightQuantizer()\n",
      "  )\n",
      "  (conv2): QuantConv2d(\n",
      "    10, 20, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (activation_quantizer): ActivationQuantizer()\n",
      "    (weight_quantizer): WeightQuantizer()\n",
      "  )\n",
      "  (fc1): QuantLinear(\n",
      "    in_features=320, out_features=50, bias=True\n",
      "    (activation_quantizer): ActivationQuantizer()\n",
      "    (weight_quantizer): WeightQuantizer()\n",
      "  )\n",
      "  (fc2): QuantLinear(\n",
      "    in_features=50, out_features=10, bias=True\n",
      "    (activation_quantizer): ActivationQuantizer()\n",
      "    (weight_quantizer): WeightQuantizer()\n",
      "  )\n",
      "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "\n",
      "***quant_model_iao***\n",
      " QuantLeNetIAO(\n",
      "  (conv1): QuantConv2d(\n",
      "    1, 10, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (activation_quantizer): SymmetricQuantizer(\n",
      "      (observer): MovingAverageMinMaxObserver()\n",
      "    )\n",
      "    (weight_quantizer): SymmetricQuantizer(\n",
      "      (observer): MinMaxObserver()\n",
      "    )\n",
      "  )\n",
      "  (conv2): QuantConv2d(\n",
      "    10, 20, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (activation_quantizer): SymmetricQuantizer(\n",
      "      (observer): MovingAverageMinMaxObserver()\n",
      "    )\n",
      "    (weight_quantizer): SymmetricQuantizer(\n",
      "      (observer): MinMaxObserver()\n",
      "    )\n",
      "  )\n",
      "  (fc1): QuantLinear(\n",
      "    in_features=320, out_features=50, bias=True\n",
      "    (activation_quantizer): SymmetricQuantizer(\n",
      "      (observer): MovingAverageMinMaxObserver()\n",
      "    )\n",
      "    (weight_quantizer): SymmetricQuantizer(\n",
      "      (observer): MinMaxObserver()\n",
      "    )\n",
      "  )\n",
      "  (fc2): QuantLinear(\n",
      "    in_features=50, out_features=10, bias=True\n",
      "    (activation_quantizer): SymmetricQuantizer(\n",
      "      (observer): MovingAverageMinMaxObserver()\n",
      "    )\n",
      "    (weight_quantizer): SymmetricQuantizer(\n",
      "      (observer): MinMaxObserver()\n",
      "    )\n",
      "  )\n",
      "  (max_pool): QuantMaxPool2d(\n",
      "    kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False\n",
      "    (activation_quantizer): SymmetricQuantizer(\n",
      "      (observer): MovingAverageMinMaxObserver()\n",
      "    )\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "\n",
      "quant_model is ready\n",
      "micronet is ready\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# some base_op, such as ``Add``、``Concat``\n",
    "from micronet.base_module.op import *\n",
    "\n",
    "# ``quantize`` is quant_module, ``QuantConv2d``, ``QuantLinear``, ``QuantMaxPool2d``, ``QuantReLU`` are quant_op\n",
    "from micronet.compression.quantization.wbwtab.quantize import QuantConv2d as quant_conv_wbwtab\n",
    "from micronet.compression.quantization.wbwtab.quantize import ActivationQuantizer as quant_relu_wbwtab\n",
    "from micronet.compression.quantization.wqaq.dorefa.quantize import QuantConv2d as quant_conv_dorefa\n",
    "from micronet.compression.quantization.wqaq.dorefa.quantize import QuantLinear as quant_linear_dorefa\n",
    "from micronet.compression.quantization.wqaq.iao.quantize import QuantConv2d as quant_conv_iao\n",
    "from micronet.compression.quantization.wqaq.iao.quantize import QuantLinear as quant_linear_iao\n",
    "from micronet.compression.quantization.wqaq.iao.quantize import QuantMaxPool2d as quant_max_pool_iao\n",
    "from micronet.compression.quantization.wqaq.iao.quantize import QuantReLU as quant_relu_iao\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pool(self.conv1(x)))\n",
    "        x = self.relu(self.max_pool(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class QuantLeNetWbWtAb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantLeNetWbWtAb, self).__init__()\n",
    "        self.conv1 = quant_conv_wbwtab(1, 10, kernel_size=5)\n",
    "        self.conv2 = quant_conv_wbwtab(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = quant_relu_wbwtab()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pool(self.conv1(x)))\n",
    "        x = self.relu(self.max_pool(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class QuantLeNetDoReFa(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantLeNetDoReFa, self).__init__()\n",
    "        self.conv1 = quant_conv_dorefa(1, 10, kernel_size=5)\n",
    "        self.conv2 = quant_conv_dorefa(10, 20, kernel_size=5)\n",
    "        self.fc1 = quant_linear_dorefa(320, 50)\n",
    "        self.fc2 = quant_linear_dorefa(50, 10)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pool(self.conv1(x)))\n",
    "        x = self.relu(self.max_pool(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class QuantLeNetIAO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantLeNetIAO, self).__init__()\n",
    "        self.conv1 = quant_conv_iao(1, 10, kernel_size=5)\n",
    "        self.conv2 = quant_conv_iao(10, 20, kernel_size=5)\n",
    "        self.fc1 = quant_linear_iao(320, 50)\n",
    "        self.fc2 = quant_linear_iao(50, 10)\n",
    "        self.max_pool = quant_max_pool_iao(kernel_size=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pool(self.conv1(x)))\n",
    "        x = self.relu(self.max_pool(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "lenet = LeNet()\n",
    "quant_lenet_wbwtab = QuantLeNetWbWtAb()\n",
    "quant_lenet_dorefa = QuantLeNetDoReFa()\n",
    "quant_lenet_iao = QuantLeNetIAO()\n",
    "\n",
    "print('***ori_model***\\n', lenet)\n",
    "print('\\n***quant_model_wbwtab***\\n', quant_lenet_wbwtab)\n",
    "print('\\n***quant_model_dorefa***\\n', quant_lenet_dorefa)\n",
    "print('\\n***quant_model_iao***\\n', quant_lenet_iao)\n",
    "\n",
    "print('\\nquant_model is ready')\n",
    "print('micronet is ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e14d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
